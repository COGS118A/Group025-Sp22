{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "You will design and execute a machine learning project. There are a few constraints on the nature of the allowed project. \n",
    "- The problem addressed will not be a \"toy problem\" or \"common training students problem\" like mtcars, iris, palmer penguins etc.\n",
    "- The dataset will have >1k observations and >5 variables. I'd prefer more like >10k observations and >10 variables. A general rule is that if you have >100x more observations than variables, your solution will likely generalize a lot better. The goal of training a supervised machine learning model is to learn the underlying pattern in a dataset in order to generalize well to unseen data, so choosing a large dataset is very important.\n",
    "\n",
    "- The project will include a model selection and/or feature selection component where you will be looking for the best setup to maximize the performance of your ML system.\n",
    "- You will evaluate the performance of your ML system using more than one appropriate metric\n",
    "- You will be writing a report describing and discussing these accomplishments\n",
    "\n",
    "\n",
    "Feel free to delete this description section when you hand in your proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peer Review\n",
    "\n",
    "You will all have an opportunity to look at the Project Proposals of other groups to fuel your creativity and get more ideas for how you can improve your own projects. \n",
    "\n",
    "Both the project proposal and project checkpoint will have peer review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Merel van den Bos\n",
    "- Alex Rivera\n",
    "- Albert Aung\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "\n",
    "Individuals leave reviews on the popular online gaming storefront Steam every day. People often go into great detail reviewing their favorite or least favorite games, making this a ripe field for sentiment analysis. Our goal is to train a model to detect the sentiment of a Steam user's review and be able to relay if this person enjoyed the game or not, and to what extent. We will be training a model with a large labelled dataset of reviews. Success will be measured by how accurately the model is able to detect whether a review is positive or negative, and if the person recommended the game or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    " \n",
    "Merel: https://www.researchgate.net/profile/Antoni-Sobkowicz/publication/311677831_Steam_Review_Dataset_-_new_large_scale_sentiment_dataset/links/5853f38408aef7d030a79745/Steam-Review-Dataset-new-large-scale-sentiment-dataset.pdf\n",
    "\n",
    "Steam is an online gaming platform which describes itself as \"the ultimate destination for playing, discussing, and creating games\" (https://store.steampowered.com/about/). According to Statista, there are approximately 120 million people that are active montly on Steam in the year 2020 which demonstrates its wide reach of audience. (https://www.statista.com/statistics/308330/number-stream-users/) As of this moment, there are about 18 million users online and 4 million users playing games on Steam. (https://store.steampowered.com/about/) These are all crazy numbers which just shows how much gaming is a part of people's lives. So how does one decide which game to dedicate their lives to or just to play for fun? This is where data and analytics come to play as users generate data and rate how each game feels for them personally. This makes up the rating of each game on Steam where there will be a positive or negative rating displayed for each game where for example Game X has a 80% positive rating showing that 80 percent of the users who rated the game enjoyed playing the game. This data which is user generated allows other players or people of interest to make their pre-emptive decisions of a game and whether they should play it or not. A user or person of interest would rather play a game with a 80 percent positive rating to a 50 percent positive rating based on conventional logic. The purpose of our study and research is to create a machine learning algorithm which deals with user ratings and decide whether it is positive or negative using sentiment analysis. This will help predict whether the user has upvoted or downvoted the game. In other words, determing the game's ratings. Why is this useful one may ask? Gaining a better understanding of user ratings and whether a user will decide to upvote or downvote a game can allow game creators and platforms to gauge whether to recommend the right games to users since the goal of the industry is to keep players interested in using the platform and the wider amount of games they become addicted to. A lot of articles online highlight the importance of the first 10 reviews since it allows it to sit on the shelve of the gaming platform (Steam) or else it stays hidden so you can see how important ratings are to games. (https://howtomarketagame.com/2022/01/25/why-your-first-10-reviews-are-the-most-important/) To add to it, the better the ratings of a game, the higher the likelihood of being featured more heavily in the front pages of the Steam so it's useful for both the companies and the platform itself to understand how well-rated a game is since it is a key indicator of their performance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Clearly describe the problem that you are solving. Avoid ambiguous words. The problem described should be well defined and should have at least one ML-relevant potential solution. Additionally, describe the problem thoroughly such that it is clear that the problem is quantifiable (the problem can be expressed in mathematical or logical terms), measurable (the problem can be measured by some metric and clearly observed), and replicable (the problem can be reproduced and occurs more than once).\n",
    " - We are going to predict the rating of a game based on Steam reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "You should have a strong idea of what dataset(s) will be used to accomplish this project. \n",
    "\n",
    "If you know what (some) of the data you will use are please give the following infomration for each dataset\n",
    "- https://www.kaggle.com/datasets/andrewmvd/steam-reviews\n",
    "- description of the size of the dataset (# of variables, # of observations): 'The dataset contains over 6.4 million publicly available reviews in English from Steam Reviews portion of Steam store run by Valve. Each review is described by review text, the id of game it belongs to, review sentiment (positive or negative) and a number of users who thought the review was helpful.'\n",
    "- what an observation consists of\n",
    "- what some critical variables are, how they are represented\n",
    "- any special handling, transformations, cleaning, etc will be needed\n",
    "\n",
    "If you don't yet know what your dataset(s) will be, you should be able to describe what you desire in terms of the above bullets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "The solution to the problem we're trying to solve is sentiment analysis since it deals with evaluating user ratings on Steam since sentiment analysis looks into studying texts and analyzing them to classify text which in our case would be binary (i.e. whether a review is positive or negative). With this information from applying sentiment analysis, we can make predictions on the ratings of each game. To do this, we will be applying different models to see which model allows us to optimize the prediction of game ratings. To do sentiment analysis, we will have to pre-process the data to reduce noise, dimensionality to improve the efficiency of the machine learning models. Some ways we look to do this by cleaning the data by switching all the words into lowercase words, removing numbers, removing stopwords and removing punctuation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms).\n",
    "\n",
    "Since the problem we are tackling is a classifcation problem (i.e. whether a rating is positive or negative), our evaluation metrics in relation to sentiment analysis will include the following: precision, recall, f-score and accuracy. Accuracy or more specifically classification accuracy can be determined by the formula (Accuracy = Number of Correct Predictions / Total number of predictions made). This measures the correctness of predictions as suggested by the formula. An equation that envelopes both precision and recall is the calculation of the F1 score which entails (F1 = 2 * 1/(1/Precision + 1/Recall)). The F1 Score tells us how precise (preicison) and how error-less our model is (recall). A high amount of precision and low amount of recall can lead to a significant number of missing instances and a low amount of precision but high amount of recall shows us inaccurate the data is but it does not miss a significant number of instances. The F1 score which ranges from [0,1] calculates and tries to tell us the balance between precision and recall. The prediction formula is given by (Precision = Number of True Positives / ( Number of True Positives + Number of False Positives)) and tells us the number of correct positive results over the number of positive results predicted by the model. The recall formula is given by ( Number of True Positives / Number of True Positives + Number of False Negatives) and tells us the number of correct positive results over the number of all samples that should have identified as positive. \n",
    "\n",
    "Source: https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination.\n",
    "\n",
    "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
    "\n",
    "Consider a tool to help you address the potential issues such as https://deon.drivendata.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We communicate through Discord where we either write each other and/or make calls, whatever is necessary for the discussion we need to have. We will also try to meet on campus in person in a while and work on the project together. \n",
    "We all respect each others way of working and we reach a consensus in good consultation. Also, we try to take everyones preferences considering topics for instance in consideration and so far this worked us very smoothly. \n",
    "When someone has a hard time makgin their deadline, we communicate this early upfront and help each other out."   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 4/18  |  7 PM |  Brainstorm topics/questions (all)  | Discuss and decide topic for the project proposal; Let everyone know when you can work on it; Set deadlines | \n",
    "| 4/24 (online chat)  |  10 PM |  Put in the file what was discussed | Help each other out where help is needed (all); Split up the work that is left | \n",
    "| 2/1  | 10 AM  | Edit, finalize, and submit proposal; Search for datasets (Beckenbaur)  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 2/14  | 6 PM  | Import & Wrangle Data ,do some EDA (Maradonna) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 2/23  | 12 PM  | Finalize wrangling/EDA; Begin programming for project (Cruyff) | Discuss/edit project code; Complete project |\n",
    "| 3/13  | 12 PM  | Complete analysis; Draft results/conclusion/discussion (Carlos)| Discuss/edit full project |\n",
    "| 3/19  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
